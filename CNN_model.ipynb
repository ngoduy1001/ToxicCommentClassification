{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install keras\n",
    "# !pip install --user keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU,Conv1D,MaxPooling1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0  ...        2006  rejected      0    0    0      0         0   \n",
       "1  ...        2006  rejected      0    0    0      0         0   \n",
       "2  ...        2006  rejected      0    0    0      0         0   \n",
       "3  ...        2006  rejected      0    0    0      0         0   \n",
       "4  ...        2006  rejected      0    0    0      1         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0              0.0                         0                         4  \n",
       "1              0.0                         0                         4  \n",
       "2              0.0                         0                         4  \n",
       "3              0.0                         0                         4  \n",
       "4              0.0                         4                        47  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and test set:\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train, train[[\"severe_toxicity\", \"obscene\", \"identity_attack\", \"insult\", \"threat\"]], test_size = 0.10, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.copy()[:10000], train.copy()[:10000][[\"severe_toxicity\", \"obscene\", \"identity_attack\", \"insult\", \"threat\"]], test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>247549</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>You put a lot of stock in the DSM, not surpris...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>42251</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>247415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>That's sad.  Back when I graduated from Duck U...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>42531</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>242421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>How did \"Civil\" choose to \"reserve\" usernames,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36937</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>243444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;3 &lt;3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37721</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>253576</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>why do you hate our inalienable rights so much...</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50579</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target                                       comment_text  \\\n",
       "4896  247549  0.200000  You put a lot of stock in the DSM, not surpris...   \n",
       "4782  247415  0.000000  That's sad.  Back when I graduated from Duck U...   \n",
       "1496  242421  0.000000  How did \"Civil\" choose to \"reserve\" usernames,...   \n",
       "1957  243444  0.000000                                              <3 <3   \n",
       "9171  253576  0.428571  why do you hate our inalienable rights so much...   \n",
       "\n",
       "      severe_toxicity  obscene  identity_attack    insult  threat  asian  \\\n",
       "4896         0.000000      0.0              0.0  0.200000     0.0    NaN   \n",
       "4782         0.000000      0.0              0.0  0.000000     0.0    NaN   \n",
       "1496         0.000000      0.0              0.0  0.000000     0.0    NaN   \n",
       "1957         0.000000      0.0              0.0  0.000000     0.0    NaN   \n",
       "9171         0.014286      0.1              0.0  0.414286     0.0    NaN   \n",
       "\n",
       "      atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "4896      NaN  ...       42251  approved      0    0    0      0         0   \n",
       "4782      NaN  ...       42531  approved      0    0    0      1         0   \n",
       "1496      NaN  ...       36937  approved      0    0    0      0         0   \n",
       "1957      NaN  ...       37721  approved      0    0    0      0         0   \n",
       "9171      NaN  ...       50579  approved      0    0    0      1         0   \n",
       "\n",
       "      sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "4896         0.000000                         0                         5  \n",
       "4782         0.000000                         0                         4  \n",
       "1496         0.000000                         0                         4  \n",
       "1957         0.000000                         0                        10  \n",
       "9171         0.071429                         0                        70  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the comments as seperate variables for further processing.\n",
    "list_sentences_train = X_train[\"comment_text\"]\n",
    "list_sentences_test = X_test[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features,char_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(list_sentences_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_sentences_test = tokenizer.texts_to_sequences(list_sentences_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17,\n",
       "  4,\n",
       "  13,\n",
       "  1,\n",
       "  16,\n",
       "  13,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  11,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  19,\n",
       "  1,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  14,\n",
       "  25,\n",
       "  1,\n",
       "  6,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  10,\n",
       "  2,\n",
       "  1,\n",
       "  12,\n",
       "  8,\n",
       "  15,\n",
       "  24,\n",
       "  1,\n",
       "  7,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  8,\n",
       "  13,\n",
       "  9,\n",
       "  16,\n",
       "  9,\n",
       "  6,\n",
       "  8,\n",
       "  6,\n",
       "  7,\n",
       "  18,\n",
       "  24,\n",
       "  29,\n",
       "  29,\n",
       "  21,\n",
       "  13,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  10,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  5,\n",
       "  3,\n",
       "  6,\n",
       "  4,\n",
       "  7,\n",
       "  5,\n",
       "  11,\n",
       "  1,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  13,\n",
       "  3,\n",
       "  2,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  19,\n",
       "  1,\n",
       "  10,\n",
       "  2,\n",
       "  5,\n",
       "  11,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  12,\n",
       "  4,\n",
       "  2,\n",
       "  8,\n",
       "  7,\n",
       "  26,\n",
       "  3,\n",
       "  1,\n",
       "  8,\n",
       "  6,\n",
       "  7,\n",
       "  14,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  3,\n",
       "  26,\n",
       "  8,\n",
       "  1,\n",
       "  7,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  21,\n",
       "  5,\n",
       "  8,\n",
       "  2,\n",
       "  12,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  17,\n",
       "  1,\n",
       "  4,\n",
       "  21,\n",
       "  30,\n",
       "  2,\n",
       "  14,\n",
       "  3,\n",
       "  6,\n",
       "  23,\n",
       "  2,\n",
       "  1,\n",
       "  11,\n",
       "  5,\n",
       "  21,\n",
       "  4,\n",
       "  9,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  17,\n",
       "  1,\n",
       "  15,\n",
       "  2,\n",
       "  5,\n",
       "  8,\n",
       "  13,\n",
       "  9,\n",
       "  2,\n",
       "  24,\n",
       "  1,\n",
       "  21,\n",
       "  13,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  14,\n",
       "  4,\n",
       "  7,\n",
       "  8,\n",
       "  2,\n",
       "  7,\n",
       "  8,\n",
       "  13,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  19,\n",
       "  1,\n",
       "  8,\n",
       "  17,\n",
       "  15,\n",
       "  16,\n",
       "  3,\n",
       "  4,\n",
       "  15,\n",
       "  8,\n",
       "  24,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  1,\n",
       "  4,\n",
       "  13,\n",
       "  3,\n",
       "  12,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  12,\n",
       "  1,\n",
       "  5,\n",
       "  16,\n",
       "  16,\n",
       "  9,\n",
       "  4,\n",
       "  5,\n",
       "  14,\n",
       "  10,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  15,\n",
       "  2,\n",
       "  12,\n",
       "  6,\n",
       "  14,\n",
       "  6,\n",
       "  7,\n",
       "  2,\n",
       "  22,\n",
       "  1,\n",
       "  17,\n",
       "  4,\n",
       "  13,\n",
       "  9,\n",
       "  1,\n",
       "  11,\n",
       "  5,\n",
       "  14,\n",
       "  25,\n",
       "  1,\n",
       "  4,\n",
       "  19,\n",
       "  1,\n",
       "  2,\n",
       "  7,\n",
       "  12,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  2,\n",
       "  15,\n",
       "  2,\n",
       "  7,\n",
       "  3,\n",
       "  1,\n",
       "  19,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  17,\n",
       "  1,\n",
       "  16,\n",
       "  5,\n",
       "  9,\n",
       "  3,\n",
       "  6,\n",
       "  14,\n",
       "  13,\n",
       "  11,\n",
       "  5,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  5,\n",
       "  7,\n",
       "  12,\n",
       "  6,\n",
       "  12,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  4,\n",
       "  3,\n",
       "  20,\n",
       "  6,\n",
       "  3,\n",
       "  10,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  12,\n",
       "  6,\n",
       "  7,\n",
       "  18,\n",
       "  24,\n",
       "  1,\n",
       "  6,\n",
       "  3,\n",
       "  26,\n",
       "  8,\n",
       "  1,\n",
       "  16,\n",
       "  9,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  17,\n",
       "  1,\n",
       "  4,\n",
       "  21,\n",
       "  23,\n",
       "  6,\n",
       "  4,\n",
       "  13,\n",
       "  8,\n",
       "  1,\n",
       "  20,\n",
       "  10,\n",
       "  6,\n",
       "  14,\n",
       "  10,\n",
       "  1,\n",
       "  20,\n",
       "  10,\n",
       "  4,\n",
       "  8,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  9,\n",
       "  2,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  17,\n",
       "  4,\n",
       "  13,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  10,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  6,\n",
       "  14,\n",
       "  1,\n",
       "  8,\n",
       "  2,\n",
       "  9,\n",
       "  23,\n",
       "  2,\n",
       "  8,\n",
       "  22]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokenized_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set length of all sentences to 500 characters. Pad zeros for sentences with length < 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_sentences_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        17,  4, 13,  1, 16, 13,  3,  1,  5,  1, 11,  4,  3,  1,  4, 19,\n",
       "         1,  8,  3,  4, 14, 25,  1,  6,  7,  1,  3, 10,  2,  1, 12,  8,\n",
       "        15, 24,  1,  7,  4,  3,  1,  8, 13,  9, 16,  9,  6,  8,  6,  7,\n",
       "        18, 24, 29, 29, 21, 13,  3,  1,  3, 10,  2,  1,  7,  5,  3,  6,\n",
       "         4,  7,  5, 11,  1,  6,  7,  8,  3,  6,  3, 13,  3,  2,  8,  1,\n",
       "         4, 19,  1, 10,  2,  5, 11,  3, 10,  1, 12,  4,  2,  8,  7, 26,\n",
       "         3,  1,  8,  6,  7, 14,  2,  1,  6,  3, 26,  8,  1,  7,  4,  3,\n",
       "         1, 21,  5,  8,  2, 12,  1,  4,  7,  1,  5,  7, 17,  1,  4, 21,\n",
       "        30,  2, 14,  3,  6, 23,  2,  1, 11,  5, 21,  4,  9,  5,  3,  4,\n",
       "         9, 17,  1, 15,  2,  5,  8, 13,  9,  2, 24,  1, 21, 13,  3,  1,\n",
       "         4,  7,  1,  5,  1, 14,  4,  7,  8,  2,  7,  8, 13,  8,  1,  4,\n",
       "        19,  1,  8, 17, 15, 16,  3,  4, 15,  8, 24,  1,  5,  7,  1,  4,\n",
       "        13,  3, 12,  5,  3,  2, 12,  1,  5, 16, 16,  9,  4,  5, 14, 10,\n",
       "         1,  3,  4,  1, 15,  2, 12,  6, 14,  6,  7,  2, 22,  1, 17,  4,\n",
       "        13,  9,  1, 11,  5, 14, 25,  1,  4, 19,  1,  2,  7, 12,  4,  9,\n",
       "         8,  2, 15,  2,  7,  3,  1, 19,  4,  9,  1,  5,  7, 17,  1, 16,\n",
       "         5,  9,  3,  6, 14, 13, 11,  5,  9,  1, 14,  5,  7, 12,  6, 12,\n",
       "         5,  3,  2,  1,  7,  4,  3, 20,  6,  3, 10,  8,  3,  5,  7, 12,\n",
       "         6,  7, 18, 24,  1,  6,  3, 26,  8,  1, 16,  9,  2,  3,  3, 17,\n",
       "         1,  4, 21, 23,  6,  4, 13,  8,  1, 20, 10,  6, 14, 10,  1, 20,\n",
       "        10,  4,  8,  2,  1,  6,  7,  3,  2,  9,  2,  8,  3,  8,  1, 17,\n",
       "         4, 13,  9,  1,  9, 10,  2,  3,  4,  9,  6, 14,  1,  8,  2,  9,\n",
       "        23,  2,  8, 22]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 240\n",
    "x = Embedding(len(tokenizer.word_index)+1, embed_size)(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv1D(filters=100,kernel_size=4,padding='same', activation='relu')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1121 22:24:40.880164 139847147374400 deprecation_wrapper.py:119] From /home/dkn019/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=MaxPooling1D(pool_size=4)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Bidirectional(GRU(60, return_sequences=True,name='lstm_layer',dropout=0.2,recurrent_dropout=0.2))(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalMaxPool1D()(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(50, activation=\"relu\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.2)(x)\n",
    "x = Dense(5, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 22:24:43.881327 139847147374400 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 240)          34080     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 100)          96100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 125, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 125, 120)          57960     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 194,445\n",
      "Trainable params: 194,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 22:24:47.921477 139847147374400 deprecation_wrapper.py:119] From /home/dkn019/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "9000/9000 [==============================] - 87s 10ms/step - loss: 0.8730 - accuracy: 0.9049 - val_loss: 0.1031 - val_accuracy: 0.9104\n",
      "Epoch 2/2\n",
      "9000/9000 [==============================] - 86s 10ms/step - loss: 0.1010 - accuracy: 0.9087 - val_loss: 0.0998 - val_accuracy: 0.9104\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_t,y_train, batch_size=batch_size, epochs=epochs,validation_data=(X_te,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_test_data = test_data[\"comment_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokenized_test_data = tokenizer.texts_to_sequences(list_sentences_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = pad_sequences(list_tokenized_submit, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97320/97320 [==============================] - 501s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_data = model.predict(X_test_data,batch_size=batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(y_test_data, columns = [\"severe_toxicity\", \"obscene\", \"identity_attack\", \"insult\", \"threat\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([test_data.reset_index(drop=True),df_results.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7097320</td>\n",
       "      <td>[ Integrity means that you pay your debts.]\\n\\...</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.025121</td>\n",
       "      <td>0.035050</td>\n",
       "      <td>0.078540</td>\n",
       "      <td>0.013952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7097321</td>\n",
       "      <td>This is malfeasance by the Administrator and t...</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.028917</td>\n",
       "      <td>0.039973</td>\n",
       "      <td>0.082723</td>\n",
       "      <td>0.016830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7097322</td>\n",
       "      <td>@Rmiller101 - Spoken like a true elitist. But ...</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.060786</td>\n",
       "      <td>0.009188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7097323</td>\n",
       "      <td>Paul: Thank you for your kind words.  I do, in...</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.037047</td>\n",
       "      <td>0.050119</td>\n",
       "      <td>0.102638</td>\n",
       "      <td>0.022696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7097324</td>\n",
       "      <td>Sorry you missed high school. Eisenhower sent ...</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.045210</td>\n",
       "      <td>0.005193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7097325</td>\n",
       "      <td>Letâ€™s see if I understand this; Berkowitz anno...</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>0.031499</td>\n",
       "      <td>0.074782</td>\n",
       "      <td>0.012031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7097326</td>\n",
       "      <td>Our oils read;  President IS taking different ...</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.021129</td>\n",
       "      <td>0.029849</td>\n",
       "      <td>0.069115</td>\n",
       "      <td>0.011906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7097327</td>\n",
       "      <td>'Work together'? Dream on. The liberals are al...</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>0.031899</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>0.012386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7097328</td>\n",
       "      <td>What would Jerry Prevo think about that story?...</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.033205</td>\n",
       "      <td>0.074774</td>\n",
       "      <td>0.013011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7097329</td>\n",
       "      <td>When wil the  indigenous  be accountable and t...</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.024371</td>\n",
       "      <td>0.034320</td>\n",
       "      <td>0.076129</td>\n",
       "      <td>0.013565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7097330</td>\n",
       "      <td>the people against O'Leary are the same people...</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>0.023502</td>\n",
       "      <td>0.033527</td>\n",
       "      <td>0.075736</td>\n",
       "      <td>0.013593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7097331</td>\n",
       "      <td>Between racist Eastman and 'Slappy' Wilson the...</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.024947</td>\n",
       "      <td>0.034302</td>\n",
       "      <td>0.077641</td>\n",
       "      <td>0.014116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7097332</td>\n",
       "      <td>Since whining is the lifeblood of online comme...</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.010130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7097333</td>\n",
       "      <td>Sue blue jeans, get out more and learn about t...</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>0.033323</td>\n",
       "      <td>0.045459</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>0.020505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7097334</td>\n",
       "      <td>This debate will never end.  However the real ...</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.029723</td>\n",
       "      <td>0.040953</td>\n",
       "      <td>0.084346</td>\n",
       "      <td>0.017716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7097335</td>\n",
       "      <td>IT IS DOA! As Collins announced her intentions...</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.027262</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.081312</td>\n",
       "      <td>0.015825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7097336</td>\n",
       "      <td>There are no words for these senseless acts.. ...</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>0.041612</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.017763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7097337</td>\n",
       "      <td>What a terrific story.  In Japan they have peo...</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.030587</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.085186</td>\n",
       "      <td>0.018178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7097338</td>\n",
       "      <td>As Donald himself said, \"Nobody knew that heal...</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.075002</td>\n",
       "      <td>0.012742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7097339</td>\n",
       "      <td>Well here we go again.  Let's continue to subs...</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.027504</td>\n",
       "      <td>0.039784</td>\n",
       "      <td>0.083502</td>\n",
       "      <td>0.016084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7097340</td>\n",
       "      <td>Let me guess, you've never been an NFL player ...</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>0.073354</td>\n",
       "      <td>0.012748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7097341</td>\n",
       "      <td>It's a black mark on the previous administrati...</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>0.030855</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>0.086670</td>\n",
       "      <td>0.018593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7097342</td>\n",
       "      <td>In the last decades the rich have god signific...</td>\n",
       "      <td>0.007037</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>0.035056</td>\n",
       "      <td>0.075802</td>\n",
       "      <td>0.014281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7097343</td>\n",
       "      <td>Kitty Piercy did her best to make the almighty...</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>0.040069</td>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7097344</td>\n",
       "      <td>Where is all that anger coming from?  A jaded ...</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.074704</td>\n",
       "      <td>0.012845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7097345</td>\n",
       "      <td>Exclude the more radical fringes on all sides ...</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.031413</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.087024</td>\n",
       "      <td>0.019222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7097346</td>\n",
       "      <td>Ignorance is bliss, ain't it?</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>0.082686</td>\n",
       "      <td>0.015650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7097347</td>\n",
       "      <td>Jjfoxy,\\nWhy would 90% of articles print fake ...</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.018057</td>\n",
       "      <td>0.026287</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.009761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7097348</td>\n",
       "      <td>Lets make some fact based statements. Half of ...</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>0.055507</td>\n",
       "      <td>0.006748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7097349</td>\n",
       "      <td>How about introducing Vukovich to you, Bob1946?</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.020330</td>\n",
       "      <td>0.055234</td>\n",
       "      <td>0.006850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97290</th>\n",
       "      <td>7194610</td>\n",
       "      <td>By selling after the budget would mean the cap...</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.023061</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.076656</td>\n",
       "      <td>0.013054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97291</th>\n",
       "      <td>7194611</td>\n",
       "      <td>This is the same person, along with Woodward, ...</td>\n",
       "      <td>0.009695</td>\n",
       "      <td>0.031212</td>\n",
       "      <td>0.042811</td>\n",
       "      <td>0.086547</td>\n",
       "      <td>0.019009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97292</th>\n",
       "      <td>7194612</td>\n",
       "      <td>Hey, Mr. Jackson.  It is what it is.  You are ...</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.021651</td>\n",
       "      <td>0.030791</td>\n",
       "      <td>0.071968</td>\n",
       "      <td>0.011833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97293</th>\n",
       "      <td>7194613</td>\n",
       "      <td>And so the fifth man, like the first four, now...</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.021501</td>\n",
       "      <td>0.031645</td>\n",
       "      <td>0.073367</td>\n",
       "      <td>0.011894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97294</th>\n",
       "      <td>7194614</td>\n",
       "      <td>The irony is delicious. Just as Trump takes me...</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.025155</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.077679</td>\n",
       "      <td>0.014161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97295</th>\n",
       "      <td>7194615</td>\n",
       "      <td>Well I am glad you like to order your flags. N...</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.021059</td>\n",
       "      <td>0.057294</td>\n",
       "      <td>0.007475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97296</th>\n",
       "      <td>7194616</td>\n",
       "      <td>I agree whole-heartedly with your Rick Lewis c...</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>0.068572</td>\n",
       "      <td>0.011842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97297</th>\n",
       "      <td>7194617</td>\n",
       "      <td>Watched the videos. The behavior I saw compare...</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>0.068340</td>\n",
       "      <td>0.011343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97298</th>\n",
       "      <td>7194618</td>\n",
       "      <td>Could you be more specific, please?</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.029008</td>\n",
       "      <td>0.040450</td>\n",
       "      <td>0.084764</td>\n",
       "      <td>0.017043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97299</th>\n",
       "      <td>7194619</td>\n",
       "      <td>Maybe we needed a different kind of President ...</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0.026938</td>\n",
       "      <td>0.037086</td>\n",
       "      <td>0.081366</td>\n",
       "      <td>0.015286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97300</th>\n",
       "      <td>7194620</td>\n",
       "      <td>This will crash around him when such loathers ...</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.030511</td>\n",
       "      <td>0.070545</td>\n",
       "      <td>0.012038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97301</th>\n",
       "      <td>7194621</td>\n",
       "      <td>Women not shopping for a day to protest what??...</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.024103</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>0.008628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97302</th>\n",
       "      <td>7194622</td>\n",
       "      <td>Yes, the alleged attempt to capture the India ...</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.034879</td>\n",
       "      <td>0.074839</td>\n",
       "      <td>0.014184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97303</th>\n",
       "      <td>7194623</td>\n",
       "      <td>There seems to be a sudden reduction of those ...</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.071642</td>\n",
       "      <td>0.012526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97304</th>\n",
       "      <td>7194624</td>\n",
       "      <td>Lifeguards are useless.</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.042467</td>\n",
       "      <td>0.058570</td>\n",
       "      <td>0.106204</td>\n",
       "      <td>0.027430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97305</th>\n",
       "      <td>7194625</td>\n",
       "      <td>Well the Dumper Post has a Indian idiot writin...</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.040417</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.017753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97306</th>\n",
       "      <td>7194626</td>\n",
       "      <td>The state PF has $60 billion so simply pay the...</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.028153</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>0.086134</td>\n",
       "      <td>0.015763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97307</th>\n",
       "      <td>7194627</td>\n",
       "      <td>She is with The Heritage Foundation, an ultra-...</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.020136</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.068232</td>\n",
       "      <td>0.011706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97308</th>\n",
       "      <td>7194628</td>\n",
       "      <td>1. You know no more than I do. It's a logical ...</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.055665</td>\n",
       "      <td>0.007311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97309</th>\n",
       "      <td>7194629</td>\n",
       "      <td>As the man said... you can teach a person how ...</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.086047</td>\n",
       "      <td>0.018071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97310</th>\n",
       "      <td>7194630</td>\n",
       "      <td>Not a day to rejoice, but a day to remember. A...</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97311</th>\n",
       "      <td>7194631</td>\n",
       "      <td>Let's look at it another way: as society begin...</td>\n",
       "      <td>0.016020</td>\n",
       "      <td>0.043309</td>\n",
       "      <td>0.057558</td>\n",
       "      <td>0.110326</td>\n",
       "      <td>0.026286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97312</th>\n",
       "      <td>7194632</td>\n",
       "      <td>I just remember a classmate of mine at Queens ...</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.040356</td>\n",
       "      <td>0.004001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97313</th>\n",
       "      <td>7194633</td>\n",
       "      <td>so very, very, sorry.</td>\n",
       "      <td>0.015939</td>\n",
       "      <td>0.044083</td>\n",
       "      <td>0.060207</td>\n",
       "      <td>0.108699</td>\n",
       "      <td>0.028551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97314</th>\n",
       "      <td>7194634</td>\n",
       "      <td>Which I addressed.  Taxes paid in the future r...</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>0.031947</td>\n",
       "      <td>0.072463</td>\n",
       "      <td>0.012674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97315</th>\n",
       "      <td>7194635</td>\n",
       "      <td>He should lose his job for promoting mis-infor...</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.025570</td>\n",
       "      <td>0.036649</td>\n",
       "      <td>0.078452</td>\n",
       "      <td>0.015512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97316</th>\n",
       "      <td>7194636</td>\n",
       "      <td>\"Thinning project is meant to lower fire dange...</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.031003</td>\n",
       "      <td>0.043047</td>\n",
       "      <td>0.086499</td>\n",
       "      <td>0.018875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97317</th>\n",
       "      <td>7194637</td>\n",
       "      <td>I hope you millennials are happy that you put ...</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.033071</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>0.090383</td>\n",
       "      <td>0.020347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97318</th>\n",
       "      <td>7194638</td>\n",
       "      <td>I'm thinking Kellyanne Conway (a.k.a. The Trum...</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.036341</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>0.015073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97319</th>\n",
       "      <td>7194639</td>\n",
       "      <td>I still can't figure why a pizza in AK cost mo...</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>0.027586</td>\n",
       "      <td>0.067033</td>\n",
       "      <td>0.010418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97320 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       comment_text  \\\n",
       "0      7097320  [ Integrity means that you pay your debts.]\\n\\...   \n",
       "1      7097321  This is malfeasance by the Administrator and t...   \n",
       "2      7097322  @Rmiller101 - Spoken like a true elitist. But ...   \n",
       "3      7097323  Paul: Thank you for your kind words.  I do, in...   \n",
       "4      7097324  Sorry you missed high school. Eisenhower sent ...   \n",
       "...        ...                                                ...   \n",
       "97315  7194635  He should lose his job for promoting mis-infor...   \n",
       "97316  7194636  \"Thinning project is meant to lower fire dange...   \n",
       "97317  7194637  I hope you millennials are happy that you put ...   \n",
       "97318  7194638  I'm thinking Kellyanne Conway (a.k.a. The Trum...   \n",
       "97319  7194639  I still can't figure why a pizza in AK cost mo...   \n",
       "\n",
       "       severe_toxicity   obscene  identity_attack    insult    threat  \n",
       "0             0.007053  0.025121         0.035050  0.078540  0.013952  \n",
       "1             0.008527  0.028917         0.039973  0.082723  0.016830  \n",
       "2             0.004193  0.016817         0.025344  0.060786  0.009188  \n",
       "3             0.013280  0.037047         0.050119  0.102638  0.022696  \n",
       "4             0.002204  0.010087         0.015840  0.045210  0.005193  \n",
       "...                ...       ...              ...       ...       ...  \n",
       "97315         0.007792  0.025570         0.036649  0.078452  0.015512  \n",
       "97316         0.009703  0.031003         0.043047  0.086499  0.018875  \n",
       "97317         0.010527  0.033071         0.045250  0.090383  0.020347  \n",
       "97318         0.007426  0.025403         0.036341  0.078056  0.015073  \n",
       "97319         0.005021  0.018944         0.027586  0.067033  0.010418  \n",
       "\n",
       "[97320 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
